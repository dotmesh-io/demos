{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import math\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOTSCIENCE_OUTPUTS=[\"input_data\"]\n",
      "DOTSCIENCE_LABELS={\"model_type\": \"data_cleaning\"}\n"
     ]
    }
   ],
   "source": [
    "print('DOTSCIENCE_OUTPUTS=[\"input_data\"]')\n",
    "print('DOTSCIENCE_LABELS={\"model_type\": \"data_cleaning\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taken data on the particulates in the air in London from (www.londonair.org.uk)[www.londonair.org.uk].\n",
    "\n",
    "In particular, we chose data on:\n",
    "* Nitric Oxide (NO)\n",
    "* Nitrogen dioxide (N2)\n",
    "* Oxides of nitrogen (NOX) \n",
    "* PM2.5 Particulate (PM2.5)\n",
    "* Sulphur Dioxide (SO2)\n",
    "\n",
    "(all measured in ug/m3).\n",
    "\n",
    "The air was sampled at Haringey Town Hall at 15 minute intervals between 1st June 2018 and 30th June 2018.\n",
    "\n",
    "[Query entered here](https://www.londonair.org.uk/london/asp/datasite.asp?CBXSpecies1=NOm&CBXSpecies2=NO2m&CBXSpecies3=NOXm&CBXSpecies5=PM25m&CBXSpecies6=SO2m&day1=1&month1=jun&year1=2018&day2=30&month2=jun&year2=2018&period=15min&ratidate=&site=HG1&res=6&Submit=Replot+graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://www.londonair.org.uk/london/asp/downloadsite.asp?site=HG1&species1=NOm&species2=NO2m&species3=NOXm&species4=PM25m&species5=SO2m&species6=&start=1-jun-2018&end=30-jun-2018&res=6&period=15min&units=ugm3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the raw data, and point Dotscience to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will put the data under version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOTSCIENCE_INPUTS=[\"gov_data_air_quality\"]\n"
     ]
    }
   ],
   "source": [
    "print('DOTSCIENCE_INPUTS=[\"gov_data_air_quality\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"raw_air_data_harringey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 00:00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 00:15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 00:30</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 00:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 01:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 01:15</td>\n",
       "      <td>1.6</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 01:30</td>\n",
       "      <td>8.1</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 01:45</td>\n",
       "      <td>1.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 02:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 02:15</td>\n",
       "      <td>6.6</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 02:30</td>\n",
       "      <td>3.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 02:45</td>\n",
       "      <td>2.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 03:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 03:15</td>\n",
       "      <td>13.3</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 03:30</td>\n",
       "      <td>3.9</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 03:45</td>\n",
       "      <td>27.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 04:00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 04:15</td>\n",
       "      <td>19.9</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 04:30</td>\n",
       "      <td>18.3</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 04:45</td>\n",
       "      <td>22.8</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 05:00</td>\n",
       "      <td>36.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 05:15</td>\n",
       "      <td>33.8</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 05:30</td>\n",
       "      <td>31.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 05:45</td>\n",
       "      <td>50.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 06:00</td>\n",
       "      <td>27.7</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 06:15</td>\n",
       "      <td>41.1</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 06:30</td>\n",
       "      <td>19.6</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 06:45</td>\n",
       "      <td>32.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 07:00</td>\n",
       "      <td>39.6</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 07:15</td>\n",
       "      <td>54.5</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13890</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 16:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 16:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13892</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13893</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 17:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13894</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 17:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13895</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 17:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13896</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13897</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 18:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13898</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 18:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13899</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 18:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13900</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 19:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13901</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 19:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13902</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 19:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 19:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13905</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 20:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 20:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13907</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 20:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13908</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 21:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13909</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 21:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13910</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 21:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13911</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 21:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13912</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 22:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13913</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 22:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13914</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 22:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13915</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 22:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13916</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 23:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13917</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 23:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13918</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 23:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13919</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>29/06/2018 23:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13920 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Site Species   ReadingDateTime  Value   Units Provisional or Ratified\n",
       "0      HG1      NO  01/06/2018 00:00    2.7  ug m-3                       P\n",
       "1      HG1      NO  01/06/2018 00:15    3.0  ug m-3                       P\n",
       "2      HG1      NO  01/06/2018 00:30    4.7  ug m-3                       P\n",
       "3      HG1      NO  01/06/2018 00:45    NaN  ug m-3                       P\n",
       "4      HG1      NO  01/06/2018 01:00    NaN  ug m-3                       P\n",
       "5      HG1      NO  01/06/2018 01:15    1.6  ug m-3                       P\n",
       "6      HG1      NO  01/06/2018 01:30    8.1  ug m-3                       P\n",
       "7      HG1      NO  01/06/2018 01:45    1.7  ug m-3                       P\n",
       "8      HG1      NO  01/06/2018 02:00    8.0  ug m-3                       P\n",
       "9      HG1      NO  01/06/2018 02:15    6.6  ug m-3                       P\n",
       "10     HG1      NO  01/06/2018 02:30    3.2  ug m-3                       P\n",
       "11     HG1      NO  01/06/2018 02:45    2.2  ug m-3                       P\n",
       "12     HG1      NO  01/06/2018 03:00    5.0  ug m-3                       P\n",
       "13     HG1      NO  01/06/2018 03:15   13.3  ug m-3                       P\n",
       "14     HG1      NO  01/06/2018 03:30    3.9  ug m-3                       P\n",
       "15     HG1      NO  01/06/2018 03:45   27.2  ug m-3                       P\n",
       "16     HG1      NO  01/06/2018 04:00    6.2  ug m-3                       P\n",
       "17     HG1      NO  01/06/2018 04:15   19.9  ug m-3                       P\n",
       "18     HG1      NO  01/06/2018 04:30   18.3  ug m-3                       P\n",
       "19     HG1      NO  01/06/2018 04:45   22.8  ug m-3                       P\n",
       "20     HG1      NO  01/06/2018 05:00   36.5  ug m-3                       P\n",
       "21     HG1      NO  01/06/2018 05:15   33.8  ug m-3                       P\n",
       "22     HG1      NO  01/06/2018 05:30   31.2  ug m-3                       P\n",
       "23     HG1      NO  01/06/2018 05:45   50.5  ug m-3                       P\n",
       "24     HG1      NO  01/06/2018 06:00   27.7  ug m-3                       P\n",
       "25     HG1      NO  01/06/2018 06:15   41.1  ug m-3                       P\n",
       "26     HG1      NO  01/06/2018 06:30   19.6  ug m-3                       P\n",
       "27     HG1      NO  01/06/2018 06:45   32.5  ug m-3                       P\n",
       "28     HG1      NO  01/06/2018 07:00   39.6  ug m-3                       P\n",
       "29     HG1      NO  01/06/2018 07:15   54.5  ug m-3                       P\n",
       "...    ...     ...               ...    ...     ...                     ...\n",
       "13890  HG1     SO2  29/06/2018 16:30    NaN  ug m-3                       P\n",
       "13891  HG1     SO2  29/06/2018 16:45    NaN  ug m-3                       P\n",
       "13892  HG1     SO2  29/06/2018 17:00    NaN  ug m-3                       P\n",
       "13893  HG1     SO2  29/06/2018 17:15    NaN  ug m-3                       P\n",
       "13894  HG1     SO2  29/06/2018 17:30    NaN  ug m-3                       P\n",
       "13895  HG1     SO2  29/06/2018 17:45    NaN  ug m-3                       P\n",
       "13896  HG1     SO2  29/06/2018 18:00    NaN  ug m-3                       P\n",
       "13897  HG1     SO2  29/06/2018 18:15    NaN  ug m-3                       P\n",
       "13898  HG1     SO2  29/06/2018 18:30    NaN  ug m-3                       P\n",
       "13899  HG1     SO2  29/06/2018 18:45    NaN  ug m-3                       P\n",
       "13900  HG1     SO2  29/06/2018 19:00    NaN  ug m-3                       P\n",
       "13901  HG1     SO2  29/06/2018 19:15    NaN  ug m-3                       P\n",
       "13902  HG1     SO2  29/06/2018 19:30    NaN  ug m-3                       P\n",
       "13903  HG1     SO2  29/06/2018 19:45    NaN  ug m-3                       P\n",
       "13904  HG1     SO2  29/06/2018 20:00    NaN  ug m-3                       P\n",
       "13905  HG1     SO2  29/06/2018 20:15    NaN  ug m-3                       P\n",
       "13906  HG1     SO2  29/06/2018 20:30    NaN  ug m-3                       P\n",
       "13907  HG1     SO2  29/06/2018 20:45    NaN  ug m-3                       P\n",
       "13908  HG1     SO2  29/06/2018 21:00    NaN  ug m-3                       P\n",
       "13909  HG1     SO2  29/06/2018 21:15    NaN  ug m-3                       P\n",
       "13910  HG1     SO2  29/06/2018 21:30    NaN  ug m-3                       P\n",
       "13911  HG1     SO2  29/06/2018 21:45    NaN  ug m-3                       P\n",
       "13912  HG1     SO2  29/06/2018 22:00    NaN  ug m-3                       P\n",
       "13913  HG1     SO2  29/06/2018 22:15    NaN  ug m-3                       P\n",
       "13914  HG1     SO2  29/06/2018 22:30    NaN  ug m-3                       P\n",
       "13915  HG1     SO2  29/06/2018 22:45    NaN  ug m-3                       P\n",
       "13916  HG1     SO2  29/06/2018 23:00    NaN  ug m-3                       P\n",
       "13917  HG1     SO2  29/06/2018 23:15    NaN  ug m-3                       P\n",
       "13918  HG1     SO2  29/06/2018 23:30    NaN  ug m-3                       P\n",
       "13919  HG1     SO2  29/06/2018 23:45    NaN  ug m-3                       P\n",
       "\n",
       "[13920 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many rows to view the entire dataframe. The records are sorted by `Species`. Let's see what unique values are in this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', 'NO2', 'NOX', 'PM2.5', 'SO2'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are five values: `NO` for nitric oxide, `NO2` for nitrogen dioxide, `NOX` for oxides of nitrogen, `Pm2.5` for PM2.5 Particulate, and `S02` for sulphur dioxide. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is each particulate measurement recorded? Let's look at the mesasurements for one timestamp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>01/06/2018 11:00</td>\n",
       "      <td>26.4</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2828</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO2</td>\n",
       "      <td>01/06/2018 11:00</td>\n",
       "      <td>44.2</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NOX</td>\n",
       "      <td>01/06/2018 11:00</td>\n",
       "      <td>84.7</td>\n",
       "      <td>ug m-3 as NO2</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8396</th>\n",
       "      <td>HG1</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>01/06/2018 11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>HG1</td>\n",
       "      <td>SO2</td>\n",
       "      <td>01/06/2018 11:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Site Species   ReadingDateTime  Value          Units  \\\n",
       "44     HG1      NO  01/06/2018 11:00   26.4         ug m-3   \n",
       "2828   HG1     NO2  01/06/2018 11:00   44.2         ug m-3   \n",
       "5612   HG1     NOX  01/06/2018 11:00   84.7  ug m-3 as NO2   \n",
       "8396   HG1   PM2.5  01/06/2018 11:00    NaN         ug m-3   \n",
       "11180  HG1     SO2  01/06/2018 11:00    NaN         ug m-3   \n",
       "\n",
       "      Provisional or Ratified  \n",
       "44                          P  \n",
       "2828                        P  \n",
       "5612                        P  \n",
       "8396                        P  \n",
       "11180                       P  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.ReadingDateTime == \"01/06/2018 11:00\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that each unique time has  five records: one for each of the particulates. Let's check that this is true in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no datetimes without sample data for all particulates: NO, NO2, NOX, PM2.5 and SO2!\n"
     ]
    }
   ],
   "source": [
    "datetimes_no_data =[]\n",
    "for date in df.ReadingDateTime:\n",
    "    if len(df.loc[df.ReadingDateTime == date]) != 5:\n",
    "        datetimes_no_data.append(date)\n",
    "        print(date)\n",
    "\n",
    "if len(datetimes_no_data) == 0:\n",
    "    print(\"no datetimes without sample data for all particulates: NO, NO2, NOX, PM2.5 and SO2!\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity check and update our datatypes\n",
    "\n",
    "We had a quick look at our dataframe above, but let's inspect its datatypes more closely. We want to make sure that any numerical data is stored in a format that we can easily perform calulations with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site                        object\n",
       "Species                     object\n",
       "ReadingDateTime             object\n",
       "Value                      float64\n",
       "Units                       object\n",
       "Provisional or Ratified     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ReadingDateTime` is saved as an `object`, which in Pandas is a string. Let's save it as a proper date so that we can later on use it in date-like operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['ReadingDateTime'] = pd.to_datetime(df['ReadingDateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site                               object\n",
       "Species                            object\n",
       "ReadingDateTime            datetime64[ns]\n",
       "Value                             float64\n",
       "Units                              object\n",
       "Provisional or Ratified            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Let's save the dataframe to CSV. Dotscience will save it as a new version, so our original CSV of the same name is still accessible if we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"raw_air_data_harringey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although every timestamp has a record for the five particulates we are interested in, from the part of the dataframe printed above it looks like a lot of these records are null (`NaN`). \n",
    "\n",
    "We want to remove null particulate `Value`s from our data. First, let's check whether any of the other columns have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site                       False\n",
       "Species                    False\n",
       "ReadingDateTime            False\n",
       "Value                       True\n",
       "Units                      False\n",
       "Provisional or Ratified    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we know that it is just the `Value` column that has some nulls. Let's see how many nulls it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5754"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Value'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how these null values are distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Null values by particulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "particulate: null values: non-null values:\n",
      "NO \t\t 62 \t\t 2722\n",
      "NO2 \t\t 62 \t\t 2722\n",
      "NOX \t\t 62 \t\t 2722\n",
      "PM2.5 \t\t 2784 \t\t 0\n",
      "SO2 \t\t 2784 \t\t 0\n"
     ]
    }
   ],
   "source": [
    "particulates = [str(array) for array in df.Species.unique()]\n",
    "\n",
    "nulls_and_nonnulls_per_particulate = zip(particulates, \n",
    "                            [len(df.loc[(df.Value.isnull()) & (df.Species == particulate)]) for particulate in particulates],\n",
    "                            [(len(df.loc[(df.Species == particulate)])) for particulate in particulates]\n",
    "                           )\n",
    "\n",
    "\n",
    "print(\"particulate: null values: non-null values:\")\n",
    "for (a, b, c) in nulls_and_nonnulls_per_particulate:\n",
    "    print(a, \"\\t\\t\", b, \"\\t\\t\", c-b)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, all of our records for PM2.5 and SO2 are null. 62 of our records for the remaining particulates are null."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and clean up the null values:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the PM2.5 and SO2 measures are null, so, first, let's remove those records altogether from our dataframe. \n",
    "\n",
    "\n",
    "The remaining particulates just have a few nulls, 62 out of 2784, or about 2%. We can probably do something useful with the remaining 98% of nonnull readings for `NO`, `NO2`, and `NOX`. Instead of treating the nulls as gaps in the data, lets replace those holes with the mean values for each respective particulate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Drop the PM2.5 and SO2 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows_to_drop = df.index[df['Species'] == \"SO2\"].tolist() + df.index[df['Species'] == \"PM2.5\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5568"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(df.index[rows_to_drop], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', 'NO2', 'NOX'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Species.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we sucessfully removed all the wholly-null particulates. Now, let's save this dataset. We'll give it a new name to distinguish it from the raw data saved earlier. Dotscience will keep track of the provenance of this new CSV, so we'll be able to easily see where and how it was created: namely, from raw_air_data_harringey.csv, via a transformation in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"nonnull_air_data_harringey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Replace sparse nulls with appropriate means\n",
    "Then, we can replace those 62 null NO, NO2 and NOX measurements with their respective particulate `Value` means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NO_rows = df.index[df['Species'] == \"NO\"].tolist()\n",
    "NO2_rows = df.index[df['Species'] == \"NO2\"].tolist()\n",
    "NOX_rows = df.index[df['Species'] == \"NOX\"].tolist()\n",
    "\n",
    "NaN_NO_locs = []\n",
    "NaN_NO2_locs = []\n",
    "NaN_NOX_locs = []\n",
    "\n",
    "for row in NO_rows:\n",
    "    if math.isnan(df.at[row, \"Value\"]):\n",
    "        NaN_NO_locs.append(row)\n",
    "        \n",
    "for row in NO2_rows:\n",
    "    if math.isnan(df.at[row, \"Value\"]):\n",
    "        NaN_NO2_locs.append(row)    \n",
    "        \n",
    "for row in NOX_rows:\n",
    "    if math.isnan(df.at[row, \"Value\"]):\n",
    "        NaN_NOX_locs.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 62 62\n"
     ]
    }
   ],
   "source": [
    "print(len(NaN_NO_locs), len(NaN_NO2_locs), len(NaN_NOX_locs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We've saved the locations of the 62 `NaN` particulate values as lists. Now lets change each of these missing particulate values to the mean value for that particulate over the time sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NO_mean = df.loc[NO_rows][\"Value\"].mean()\n",
    "NO2_mean = df.loc[NO2_rows][\"Value\"].mean()\n",
    "NOX_mean = df.loc[NOX_rows][\"Value\"].mean()\n",
    "\n",
    "# loop through the values, updating the NaNs to the respective mean values\n",
    "for nan_loc in NaN_NO_locs:\n",
    "    df.at[nan_loc, 'Value'] = NO_mean\n",
    "    \n",
    "for nan_loc in NaN_NO2_locs:\n",
    "    df.at[nan_loc, 'Value'] = NO2_mean\n",
    "\n",
    "for nan_loc in NaN_NOX_locs:\n",
    "    df.at[nan_loc, 'Value'] = NOX_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have removed or updated all the null values. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Value'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's celebrate by saving the null-free dataframe. We can overwrite the previous `nonnull_air_data_harringey.csv` safe in the knowledge dotsience will save the version history, so we can always roll back to the earlier version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"nonnull_air_data_harringey.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a second look at the columns of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:00:00</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:15:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:30:00</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:45:00</td>\n",
       "      <td>13.953012</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG1</td>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 01:00:00</td>\n",
       "      <td>13.953012</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site Species     ReadingDateTime      Value   Units Provisional or Ratified\n",
       "0  HG1      NO 2018-01-06 00:00:00   2.700000  ug m-3                       P\n",
       "1  HG1      NO 2018-01-06 00:15:00   3.000000  ug m-3                       P\n",
       "2  HG1      NO 2018-01-06 00:30:00   4.700000  ug m-3                       P\n",
       "3  HG1      NO 2018-01-06 00:45:00  13.953012  ug m-3                       P\n",
       "4  HG1      NO 2018-01-06 01:00:00  13.953012  ug m-3                       P"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to know the `Site` values in this case, since all our records are from the same location. So, let's drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns='Site', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>ReadingDateTime</th>\n",
       "      <th>Value</th>\n",
       "      <th>Units</th>\n",
       "      <th>Provisional or Ratified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:00:00</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:15:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:30:00</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 00:45:00</td>\n",
       "      <td>13.953012</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>2018-01-06 01:00:00</td>\n",
       "      <td>13.953012</td>\n",
       "      <td>ug m-3</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species     ReadingDateTime      Value   Units Provisional or Ratified\n",
       "0      NO 2018-01-06 00:00:00   2.700000  ug m-3                       P\n",
       "1      NO 2018-01-06 00:15:00   3.000000  ug m-3                       P\n",
       "2      NO 2018-01-06 00:30:00   4.700000  ug m-3                       P\n",
       "3      NO 2018-01-06 00:45:00  13.953012  ug m-3                       P\n",
       "4      NO 2018-01-06 01:00:00  13.953012  ug m-3                       P"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's save this data once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"air_data_harringey_streamlined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## hacky summary stat used to try to get a commit made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOTSCIENCE_PARAMETERS={\"features\": \"blah\"}\n",
      "DOTSCIENCE_SUMMARY={\"thing\": 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print('DOTSCIENCE_PARAMETERS=' + json.dumps({\"features\": \"blah\"}))\n",
    "\n",
    "print('DOTSCIENCE_SUMMARY=' + json.dumps({\"thing\": 1}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
